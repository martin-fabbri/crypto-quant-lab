{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import temporian as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = tp.from_parquet(\n",
    "    \"../../data/ecommerce_sales.parquet\",\n",
    "    timestamps=\"InvoiceDate\",\n",
    ")\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[\"TotalPrice\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common operation on temporal data is to calculate the moving sum. Let's calculate and plot the sum of sales for each transaction in the previous seven days. The moving sum can be computed using the moving_sum operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_sales = sales[\"TotalPrice\"].moving_sum(tp.duration.days(7))\n",
    "weekly_sales.plot(interactive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales per products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_per_product = sales.add_index(\"StockCode\")\n",
    "weekly_sales_per_product = sales_per_product[\"TotalPrice\"].moving_sum(\n",
    "    tp.duration.days(7)\n",
    ")\n",
    "weekly_sales_per_product.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate transactions into time series\n",
    "Our dataset contains individual client transactions. To use this data with a machine learning model, it is often useful to aggregate it into time series, where the data is sampled uniformly over time. For example, we could aggregate the sales weekly, or calculate the total sales in the last week for each day.\n",
    "\n",
    "However, it is important to note that aggregating transaction data into time series can result in some data loss. For example, the individual transaction timestamps and values would be lost. This is because the aggregated time series would only represent the total sales for each time period.\n",
    "\n",
    "Let's compute the total sales in the last week for each day for each product individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sampling = sales_per_product.tick(tp.duration.days(1))\n",
    "weekly_sales_daily = sales_per_product[\"TotalPrice\"].moving_sum(\n",
    "    tp.duration.days(7), sampling=daily_sampling\n",
    ")\n",
    "weekly_sales_daily.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.to_pandas(weekly_sales_daily)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a forecasting model with TensorFlow model\n",
    "\n",
    "A key application of Temporian is to clean data and perform feature engineering for machine learning models. It is well suited for forecasting, anomaly detection, fraud detection, and other tasks where data comes continuously.\n",
    "\n",
    "In this example, we show how to train a TensorFlow model to predict the next day's sales using past sales for each product individually. We will feed the model various levels of aggregations of sales as well as calendar information.\n",
    "\n",
    "Let's first augment our dataset and convert it to a dataset compatible with a tabular ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_per_product = sales.add_index(\"StockCode\")\n",
    "daily_sampling = sales_per_product.tick(tp.duration.days(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute moving sums with various window length.\n",
    "Machine learning models are able to select the ones that matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    sales_per_product[\"TotalPrice\"]\n",
    "    .moving_sum(tp.duration.days(w), sampling=daily_sampling)\n",
    "    .rename(f\"moving_sum_{w}\")\n",
    "    for w in [3, 7, 14, 28]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calendar information such as the day of the week are very informative of human activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.append(daily_sampling.calendar_day_of_week())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label is the daly sales shifted / leaked one days in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = (\n",
    "    sales_per_product[\"UnitPrice\"]\n",
    "    .leak(tp.duration.days(1))\n",
    "    .moving_sum(tp.duration.days(1), sampling=daily_sampling)\n",
    "    .rename(\"label\")\n",
    ")\n",
    "dataset = tp.glue(*features, label)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then convert the dataset from EventSet to TensorFlow Dataset format, and train a Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "\n",
    "def extract_label(example):\n",
    "    example.pop(\"timestamp\")\n",
    "    label = example.pop(\"label\")\n",
    "    return example, label\n",
    "\n",
    "\n",
    "tf_dataset = tp.to_tensorflow_dataset(dataset).map(extract_label).batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tfdf.keras.RandomForestModel(task=tfdf.keras.Task.REGRESSION, verbose=2)\n",
    "model.fit(tf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdf.model_plotter.plot_model_in_colab(model, tree_idx=0, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdf.model_plotter.plot_model(model, tree_idx=0, max_depth=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
